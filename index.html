<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="UTF-8">
  <title>Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬ÙˆÙ‡</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      margin: 0;
      font-family: sans-serif;
      text-align: center;
      background: #f0f0f0;
    }
    h2 {
      color: #006233;
      margin-top: 10px;
    }
    .video-container {
      position: relative;
      display: inline-block;
    }
    video, canvas {
      width: 100%;
      max-width: 320px;
      border: 2px solid #006233;
      border-radius: 12px;
      margin-top: 15px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
  <h2>ğŸ“¸ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬ÙˆÙ‡</h2>
  <div class="video-container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    let labeledFaceDescriptors = [];

    // Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: 'environment' },
            width: { ideal: 320 },
            height: { ideal: 240 }
          },
          audio: false
        });
        video.srcObject = stream;
      } catch (err) {
        alert("âš ï¸ ØªØ¹Ø°Ø± ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§: " + err.message);
        console.error(err);
      }
    }

    // ØªØ­Ù…ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø£ÙˆØµØ§Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡
    async function loadLabeledImages() {
      const labels = ['adel', 'ÙØ§Ø·Ù…Ø©', 'imad']; // Ø¶Ø¹ Ù‡Ù†Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµÙˆØ± Ø¨Ø¯ÙˆÙ† .jpg

      return Promise.all(
        labels.map(async label => {
          const imgUrl = `students/${label}.jpg`;
          const img = await faceapi.fetchImage(imgUrl);
          const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();

          if (!detection) {
            console.warn(`âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ ØµÙˆØ±Ø© ${label}`);
            return null;
          }

          return new faceapi.LabeledFaceDescriptors(label, [detection.descriptor]);
        })
      ).then(descriptors => descriptors.filter(Boolean)); // Ø­Ø°Ù Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ÙØ§Ø±ØºØ©
    }

    async function initFaceRecognition() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js/models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js/models');

      labeledFaceDescriptors = await loadLabeledImages();
      if (!labeledFaceDescriptors.length) {
        alert("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ ÙˆØ¬Ù‡ Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„ÙŠÙ‡.");
        return;
      }

      const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.6);

      video.addEventListener('play', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        faceapi.matchDimensions(canvas, displaySize);
        const ctx = canvas.getContext('2d');

        setInterval(async () => {
          if (video.paused || video.ended) return;

          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();

          const resizedDetections = faceapi.resizeResults(detections, displaySize);
          ctx.clearRect(0, 0, canvas.width, canvas.height);

          resizedDetections.forEach(detection => {
            const match = faceMatcher.findBestMatch(detection.descriptor);
            const box = detection.detection.box;
            const drawBox = new faceapi.draw.DrawBox(box, { label: match.toString(), boxColor: '#006233' });
            drawBox.draw(canvas);
          });
        }, 500); // ÙƒÙ„ Ù†ØµÙ Ø«Ø§Ù†ÙŠØ©
      });
    }

    window.addEventListener('DOMContentLoaded', async () => {
      await startVideo();
      await initFaceRecognition();
    });
  </script>
</body>
</html>
